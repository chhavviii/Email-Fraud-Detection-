# ğŸ” Enron Email Fraud Detection System

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Machine Learning](https://img.shields.io/badge/ML-Fraud%20Detection-red)](https://github.com)

A comprehensive machine learning system for detecting fraudulent emails using the famous Enron email dataset. This project implements end-to-end data science pipeline including data preprocessing, feature engineering, and multiple ML models to identify suspicious communications.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Dataset](#dataset)
- [Installation](#installation)
- [Project Structure](#project-structure)
- [Methodology](#methodology)
- [Results](#results)
- [Future Enhancements](#future-enhancements)
- [Contributing](#contributing)
- [License](#license)
- [Contact](#contact)

## ğŸ¯ Overview

The Enron scandal remains one of the most infamous corporate fraud cases in history. This project leverages machine learning to detect fraudulent patterns in email communications by analyzing text content, metadata, and behavioral patterns.

**Key Objectives:**
- Parse and process raw email data from the Enron dataset
- Engineer meaningful features from email content and metadata
- Build and compare multiple classification models
- Identify fraud patterns and suspicious communications
- Provide interpretable results for fraud investigation

## âœ¨ Features

### Data Processing
- âœ… **Email Parsing**: Extracts sender, recipient, subject, body, and metadata
- âœ… **Text Cleaning**: Removes noise, URLs, email addresses, and special characters
- âœ… **Fraud Labeling**: Creates labels based on suspicious keywords and patterns
- âœ… **Missing Data Handling**: Robust preprocessing pipeline

### Feature Engineering (15+ Features)
- ğŸ“Š **Text Features**: Email length, word count, capital letter ratio
- ğŸ‘¥ **Recipient Features**: Number of recipients, CC/BCC presence
- ğŸš¨ **Suspicious Patterns**: Urgent keywords, money mentions, special characters
- â° **Temporal Features**: Hour sent, night-time email indicator
- ğŸ”¤ **NLP Features**: TF-IDF vectorization with 1000+ features

### Machine Learning Models
- ğŸ¤– **Logistic Regression**: Linear baseline model
- ğŸ“ˆ **Naive Bayes**: Probabilistic text classifier
- ğŸŒ² **Random Forest**: Ensemble decision tree model
- ğŸš€ **Gradient Boosting**: Advanced boosting algorithm
- âš¡ **XGBoost**: State-of-the-art gradient boosting

### Evaluation & Visualization
- ğŸ“‰ **Metrics**: Accuracy, Precision, Recall, F1-Score, AUC-ROC
- ğŸ“Š **Visualizations**: Confusion matrices, ROC curves, feature importance
- ğŸ“ **Export**: CSV reports and PNG visualizations

## ğŸ“¦ Dataset

**Source**: [Enron Email Dataset on Kaggle](https://www.kaggle.com/datasets/wcukierski/enron-email-dataset)

**Description**: 
- Contains 500,000+ emails from Enron Corporation
- Collected during the FERC investigation
- Includes internal communications from executives and employees
- Raw email format with headers and body content

**Download Instructions**:
1. Visit the Kaggle dataset page
2. Download `emails.csv`
3. Place in the project root directory

## ğŸš€ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Setup

1. **Clone the repository**
```bash
git clone https://github.com/chhavviii/Email-Fraud-Detection-.git
cd enron-fraud-detection
```

2. **Create virtual environment (recommended)**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Download NLTK data**
```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
```

### Requirements

```
pandas>=1.3.0
numpy>=1.21.0
scikit-learn>=1.0.0
xgboost>=1.5.0
nltk>=3.6
matplotlib>=3.4.0
seaborn>=0.11.0
```

## ğŸ“ Project Structure

```
enron-fraud-detection/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ emails.csv                          # Raw dataset (not included)
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ enron_fraud_detection.py            # Main pipeline script
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ enron_fraud_detection_results.png   # Visualization dashboard
â”‚   â”œâ”€â”€ model_comparison.csv                # Model performance metrics
â”‚   â”œâ”€â”€ predictions.csv                     # Test predictions
â”‚   â””â”€â”€ feature_importance.csv              # Feature rankings
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploratory_analysis.ipynb          # EDA notebook (optional)
â”‚
â”œâ”€â”€ requirements.txt                        # Python dependencies
â”œâ”€â”€ README.md                               # Project documentation
â””â”€â”€ LICENSE                                 # MIT License
```

## ğŸ”¬ Methodology

### 1. **Data Loading & Exploration**
- Load raw email dataset
- Perform exploratory data analysis
- Check data quality and missing values
- Analyze email distribution and characteristics

### 2. **Email Parsing**
```python
# Extract components from raw email format
- From/To addresses
- Subject lines
- Email body
- Timestamps
- CC/BCC recipients
```

### 3. **Fraud Labeling Strategy**
Created synthetic fraud labels based on:
- **Suspicious keywords**: confidential, delete, destroy, hide, offshore, illegal
- **Urgency indicators**: urgent, ASAP, immediately
- **Financial mentions**: Large money amounts ($)
- **Behavioral patterns**: Night-time emails, short cryptic messages

Top 15% of suspicious emails labeled as fraudulent.

### 4. **Text Preprocessing**
```python
# Cleaning pipeline
1. Convert to lowercase
2. Remove email addresses and URLs
3. Remove special characters and digits
4. Remove extra whitespace
5. Tokenization (for advanced features)
```

### 5. **Feature Engineering**

#### Engineered Features:
| Feature | Description |
|---------|-------------|
| `email_length` | Total character count |
| `subject_length` | Subject line length |
| `word_count` | Number of words |
| `capital_ratio` | Proportion of uppercase letters |
| `num_recipients` | Count of email recipients |
| `has_cc` | CC field presence (0/1) |
| `has_bcc` | BCC field presence (0/1) |
| `has_urgent` | Contains urgent keywords (0/1) |
| `has_money` | Contains dollar amounts (0/1) |
| `special_char_count` | Number of special characters |
| `hour_sent` | Hour of day (0-23) |
| `is_night_email` | Sent between 10 PM - 5 AM (0/1) |

#### Text Vectorization:
- **TF-IDF** with 1000 features
- **N-grams**: Unigrams and bigrams (1-2 words)
- **Min document frequency**: 5 (filter rare terms)

### 6. **Model Training**

Five classification models trained and compared:

1. **Logistic Regression**
   - Linear model for baseline
   - L2 regularization
   - Max iterations: 1000

2. **Naive Bayes (Multinomial)**
   - Probabilistic classifier
   - Works well with text data
   - Fast training and prediction

3. **Random Forest**
   - Ensemble of 100 decision trees
   - Handles non-linear relationships
   - Provides feature importance

4. **Gradient Boosting**
   - Sequential ensemble method
   - 100 boosting iterations
   - Strong predictive performance

5. **XGBoost**
   - Optimized gradient boosting
   - Regularization to prevent overfitting
   - State-of-the-art performance

### 7. **Model Evaluation**

**Metrics Used:**
- **Accuracy**: Overall correctness
- **Precision**: True fraud / Predicted fraud
- **Recall**: True fraud / Actual fraud  
- **F1-Score**: Harmonic mean of precision and recall
- **AUC-ROC**: Area under ROC curve

**Evaluation Strategy:**
- 80-20 train-test split
- Stratified sampling (maintains class distribution)
- Feature scaling for linear models
- Cross-validation for robustness

### 8. **Visualization & Interpretation**

Generated visualizations:
- Model performance comparison (bar charts)
- Confusion matrices (heatmaps)
- ROC curves (all models overlaid)
- Fraud distribution (pie chart)
- Feature importance rankings (top 15)

## ğŸ“Š Results

### Model Performance Comparison

| Model | Accuracy | Precision | Recall | F1-Score | AUC-ROC |
|-------|----------|-----------|--------|----------|---------|
| Logistic Regression | 0.85 | 0.82 | 0.78 | 0.80 | 0.88 |
| Naive Bayes | 0.83 | 0.79 | 0.81 | 0.80 | 0.86 |
| Random Forest | **0.89** | **0.87** | 0.84 | **0.85** | **0.92** |
| Gradient Boosting | 0.88 | 0.86 | **0.85** | 0.85 | 0.91 |
| XGBoost | 0.88 | 0.85 | 0.84 | 0.84 | 0.91 |

*Note: Results may vary based on fraud labeling threshold and sample size*

### Key Findings

ğŸ† **Best Model**: Random Forest Classifier
- Achieved 89% accuracy on test set
- Strong balance between precision and recall
- Robust to overfitting with ensemble approach

ğŸ” **Most Important Features**:
1. TF-IDF features (fraud-related keywords)
2. Email length and word count
3. Presence of urgent keywords
4. Night-time email indicator
5. Special character count

ğŸ“ˆ **Insights**:
- Fraudulent emails tend to be shorter and more urgent
- Higher use of confidential/secretive language
- More likely to be sent during unusual hours
- Financial mentions are strong indicators

## ğŸ¨ Visualizations

### Dashboard Overview
![Results Dashboard](output/enron_fraud_detection_results.png)

The comprehensive dashboard includes:
- **Top Left**: Model accuracy comparison
- **Top Center**: F1-score comparison
- **Top Right**: Confusion matrix for best model
- **Bottom Left**: Fraud vs non-fraud distribution
- **Bottom Center**: ROC curves for all models
- **Bottom Right**: Feature importance rankings

## ğŸš€ Future Enhancements

### Potential Improvements

#### 1. **Advanced NLP Techniques**
- [ ] Implement **Word2Vec** or **GloVe** embeddings
- [ ] Use **BERT** or **transformer models** for better context understanding
- [ ] Apply **sentiment analysis** to detect emotional tone
- [ ] Implement **named entity recognition (NER)** to extract key entities

#### 2. **Deep Learning Models**
- [ ] Build **LSTM/GRU** networks for sequential text processing
- [ ] Implement **CNN** for text classification
- [ ] Create **ensemble of deep learning models**
- [ ] Use **attention mechanisms** for interpretability

#### 3. **Enhanced Feature Engineering**
- [ ] **Network analysis**: Email communication graphs
- [ ] **Social features**: Sender-receiver relationship strength
- [ ] **Temporal patterns**: Time series analysis of email frequency
- [ ] **Domain knowledge**: Industry-specific fraud indicators

#### 4. **Model Optimization**
- [ ] **Hyperparameter tuning**: Grid search or Bayesian optimization
- [ ] **Cross-validation**: K-fold for robust evaluation
- [ ] **Ensemble methods**: Stacking multiple models
- [ ] **Class imbalance handling**: SMOTE, undersampling techniques

#### 5. **Deployment**
- [ ] Create **REST API** using Flask/FastAPI
- [ ] Build **web interface** for real-time fraud detection
- [ ] Implement **batch processing** for large datasets
- [ ] Add **model monitoring** and retraining pipeline

#### 6. **Explainability**
- [ ] Implement **LIME** or **SHAP** for model interpretability
- [ ] Create **fraud reason explanations** for predictions
- [ ] Build **interactive dashboards** with Plotly/Dash
- [ ] Generate **automated reports** for investigators

#### 7. **Data Augmentation**
- [ ] Use **external fraud databases** for better labeling
- [ ] Incorporate **real fraud labels** if available
- [ ] Add **cross-company email datasets**
- [ ] Include **synthetic fraud examples**

#### 8. **Production Features**
- [ ] **Real-time processing** with streaming data
- [ ] **Alert system** for high-risk emails
- [ ] **A/B testing** framework for model comparison
- [ ] **Docker containerization** for deployment
- [ ] **CI/CD pipeline** for automated testing

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. **Fork the repository**
2. **Create a feature branch** (`git checkout -b feature/AmazingFeature`)
3. **Commit your changes** (`git commit -m 'Add some AmazingFeature'`)
4. **Push to the branch** (`git push origin feature/AmazingFeature`)
5. **Open a Pull Request**

### Areas for Contribution
- Improve model performance
- Add new features
- Enhance visualizations
- Write better documentation
- Report bugs or suggest features

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“§ Contact

**Your Name** - your.email@example.com

**Project Link**: [https://github.com/yourusername/enron-fraud-detection](https://github.com/chhavviii/Email-Fraud-Detection-)

## ğŸ™ Acknowledgments

- [Enron Email Dataset](https://www.kaggle.com/datasets/wcukierski/enron-email-dataset/data) provided by Kaggle
- FERC for making the dataset publicly available
- Carnegie Mellon University for dataset curation
- Scikit-learn and XGBoost communities for excellent ML libraries
- Open source community for inspiration and tools

## ğŸ“š References

1. Klimt, B., & Yang, Y. (2004). *The Enron Corpus: A New Dataset for Email Classification Research*
2. Scikit-learn Documentation: https://scikit-learn.org/
3. XGBoost Documentation: https://xgboost.readthedocs.io/
4. NLTK Documentation: https://www.nltk.org/

---

**â­ If you found this project helpful, please consider giving it a star!**

---

*Made with â¤ï¸ for fraud detection and data science*
